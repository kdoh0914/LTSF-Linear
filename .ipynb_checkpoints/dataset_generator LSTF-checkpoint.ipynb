{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73bcbba4-cf7a-4254-9558-d89c17af2f99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# This code is to make *.csv dataset for LSTF from long wav files\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import csv\n",
    "import datetime\n",
    "import progressbar\n",
    "\n",
    "SR=22050\n",
    "\n",
    "\n",
    "def convert_audio_to_csv(audio_file, output_file):\n",
    "    # Load the audio file\n",
    "    SR = 22050  # Assuming a sample rate of 22050 (replace with your desired value)\n",
    "    y, sr = librosa.load(audio_file, sr=SR, duration=10)\n",
    "\n",
    "    # Create a progress bar\n",
    "    prog_bar = progressbar.ProgressBar(maxval=len(y))\n",
    "\n",
    "    # Convert the audio to a CSV file\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "        # Write the header\n",
    "        writer.writerow(['timeframe', 'frame_number', 'data'])\n",
    "        prog_bar.start()\n",
    "\n",
    "        # Write the audio data to the CSV file\n",
    "        for i in range(len(y)):\n",
    "            timeframe = i / sr\n",
    "            frame_number = i\n",
    "            time_struct = datetime.timedelta(seconds=timeframe)\n",
    "\n",
    "            # Extract hours, minutes, and seconds directly from the timedelta object\n",
    "            hours, remainder = divmod(time_struct.seconds, 3600)\n",
    "            minutes, seconds = divmod(remainder, 60)\n",
    "            formatted_timeframe = f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "            writer.writerow([formatted_timeframe, frame_number, y[i]])\n",
    "            prog_bar.update(i + 1)  # Update the progress bar with the current index\n",
    "        \n",
    "        prog_bar.finish()\n",
    "\n",
    "            \n",
    "            \n",
    "# Settings\n",
    "audio_y_file = '/anc/data0213/audio_y.wav' # reverse audio of x2\n",
    "audio_x1_file = '/anc/data0213/audio_x1.wav' # upstream recorded\n",
    "audio_x2_file = '/anc/data0213/audio_x2.wav' # downstream recorded\n",
    "event_file = '/hifi-gan/yolo7_detection/detection_results.txt' # event file(txt file). shape is (: , 4)\n",
    "output_dir = '/LTSF-Linear/dataset'\n",
    "dataset_csv = '/LTSF-Linear/dataset/audio_x2.csv'\n",
    "teacher_dir = '/hifi-gan/yolo7_detection/noise_speech_data/teacher' # for fine tuning\n",
    "min_length_frames = SR*2 ## 2sec\n",
    "#total_length_frames = 215649000 ## 9780초\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the wav file\n",
    "\n",
    "convert_audio_to_csv(audio_x2_file, dataset_csv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51484dca-73ec-423e-bd38-f634b8bf6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "fps = 30\n",
    "\n",
    "\n",
    "audio_y, sr = librosa.load(audio_y_file, sr=SR)\n",
    "print('dimension of audio y :', audio_y.shape[0])\n",
    "print('time of audio(sec) : ', audio_y.shape[0]/SR)\n",
    "print('time of audio(min) : ', audio_y.shape[0]/SR/60)\n",
    "\n",
    "# Load the text file with specified columns and replace \"_\" in first column\n",
    "data = np.genfromtxt(event_file, delimiter=',', dtype=None, encoding=None)\n",
    "\n",
    "# Remove \"_\" from first column and convert to integer\n",
    "data['f0'] = np.char.replace(data['f0'], \"_\", \"\").astype(int)\n",
    "print('dimension of text data :', data.shape)\n",
    "print(data[0:5])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fd5d098-c4d9-415b-a8d3-8eac3d769db3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write the file until x1_segment_0.wav\n",
      "write the file until x1_segment_1.wav\n",
      "write the file until x1_segment_2.wav\n",
      "write the file until x1_segment_3.wav\n",
      "write the file until x1_segment_4.wav\n",
      "write the file until x1_segment_5.wav\n",
      "write the file until x1_segment_6.wav\n",
      "write the file until x1_segment_7.wav\n",
      "write the file until x1_segment_8.wav\n",
      "write the file until x1_segment_9.wav\n",
      "write the file until x1_segment_10.wav\n",
      "write the file until x1_segment_11.wav\n",
      "write the file until x1_segment_12.wav\n",
      "write the file until x1_segment_13.wav\n",
      "write the file until x1_segment_14.wav\n",
      "write the file until x1_segment_15.wav\n",
      "write the file until x1_segment_16.wav\n",
      "write the file until x1_segment_17.wav\n",
      "write the file until x1_segment_18.wav\n",
      "write the file until x1_segment_19.wav\n",
      "write the file until x1_segment_20.wav\n",
      "write the file until x1_segment_21.wav\n",
      "write the file until x1_segment_22.wav\n",
      "write the file until x1_segment_23.wav\n",
      "write the file until x1_segment_24.wav\n",
      "write the file until x1_segment_25.wav\n",
      "write the file until x1_segment_26.wav\n",
      "write the file until x1_segment_27.wav\n",
      "write the file until x1_segment_28.wav\n",
      "write the file until x1_segment_29.wav\n",
      "write the file until x1_segment_30.wav\n",
      "write the file until x1_segment_31.wav\n",
      "write the file until x1_segment_32.wav\n",
      "write the file until x1_segment_33.wav\n",
      "write the file until x1_segment_34.wav\n",
      "write the file until x1_segment_35.wav\n",
      "write the file until x1_segment_36.wav\n",
      "write the file until x1_segment_37.wav\n",
      "write the file until x1_segment_38.wav\n",
      "write the file until x1_segment_39.wav\n",
      "write the file until x1_segment_40.wav\n",
      "write the file until x1_segment_41.wav\n",
      "write the file until x1_segment_42.wav\n",
      "write the file until x1_segment_43.wav\n",
      "write the file until x1_segment_44.wav\n",
      "write the file until x1_segment_45.wav\n",
      "write the file until x1_segment_46.wav\n",
      "write the file until x1_segment_47.wav\n",
      "write the file until x1_segment_48.wav\n",
      "write the file until x1_segment_49.wav\n",
      "Noise speech data has been made.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Loop through the audio file with a step of segment_duration_s\n",
    "segment_duration_s = 2  # 2 seconds\n",
    "audio_duration_s = len(audio_x1) / SR\n",
    "\n",
    "# From config_v3.json, Hifi-GAN\n",
    "n_fft = 1024\n",
    "hop_size = 256\n",
    "win_size = 1024\n",
    "num_mels = 80\n",
    "sampling_rate = SR\n",
    "fmin = 0\n",
    "fmax = 8000\n",
    "\n",
    "# Create a list to store the metadata for each segment\n",
    "metadata = []\n",
    "\n",
    "for i in range(0, int(audio_duration_s - 100), segment_duration_s):\n",
    "    # Extract the segment\n",
    "    start_sample = i * SR\n",
    "    end_sample = (i + segment_duration_s) * SR\n",
    "    segment = audio_x1[start_sample:end_sample]\n",
    "    \n",
    "    # for Fine tuning .npy\n",
    "    segment_y = audio_y[start_sample:end_sample]\n",
    "    \n",
    "    # From meldataset.py\n",
    "    segment_y = torch.FloatTensor(segment_y)\n",
    "    segment_y = segment_y.unsqueeze(0)\n",
    "    \n",
    "    mel_spec = mel_spectrogram(segment_y, n_fft, num_mels, sampling_rate, hop_size, win_size, fmin, fmax, center=False)\n",
    "\n",
    "    #### 이전 버전 작업인데 차원이 맞지 않아서, Hifi-GAN에 있는 함수를 쓰기로.\n",
    "    #mel_spec = librosa.feature.melspectrogram(y=segment_y, sr=SR, n_mels=80, hop_length=256, n_fft=1024)\n",
    "    #mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # Save the segment\n",
    "    segment_name = f\"x1_segment_{i // segment_duration_s}.wav\"\n",
    "    segment_name_meta = f\"x1_segment_{i // segment_duration_s}\"\n",
    "    sf.write(segment_name, segment, SR)\n",
    "    \n",
    "    #파일 이름이 x1(입력과 동일한)으로 되어야 fine tuning이 동작됨.\n",
    "    segment_name_y = f\"x1_segment_{i // segment_duration_s}.npy\"\n",
    "    np.save(segment_name_y, mel_spec)\n",
    "    \n",
    "    if i & 100 == 0 :\n",
    "        print (f'progress on making training file until {segment_name}...') \n",
    "    \n",
    "    # Find the corresponding rows in the text file\n",
    "    start_time = i  # convert seconds to frames\n",
    "    end_time = i + segment_duration_s  # convert seconds to frames\n",
    "    frame_start = start_time * fps  # convert time to frames\n",
    "    frame_end = end_time * fps  # convert time to frames\n",
    "\n",
    "    # Select rows where the frame number is within the start and end frames\n",
    "    segment_metadata = data[(data['f0'].astype(int) >= frame_start) & (data['f0'].astype(int) < frame_end)]\n",
    "\n",
    "    # Keep only the columns you want (excluding the second and ninth)\n",
    "    segment_metadata = segment_metadata[['f2', 'f3', 'f4', 'f5', 'f6', 'f7']]\n",
    "    metadata_line = segment_name_meta\n",
    "    \n",
    "    # Add the segment metadata to the list\n",
    "    print('Start to making metadata..')\n",
    "    for j, row in enumerate(segment_metadata):\n",
    "        metadata_row = ', '.join(map(str, row))\n",
    "        if j == 0:\n",
    "            metadata_line += \"|\" + metadata_row\n",
    "        else:\n",
    "            metadata_line += \", \" + metadata_row\n",
    "    metadata.append(metadata_line)\n",
    "\n",
    "\n",
    "with open(\"metadata.txt\", 'w') as f:\n",
    "    for line in metadata:\n",
    "        f.write(line + \"\\n\")\n",
    "        \n",
    "print('Noise speech data has been made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29feda2-64c8-4f25-ab1c-61ea1b025b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, validation and test data has been made.\n"
     ]
    }
   ],
   "source": [
    "# To Split train and validation data\n",
    "\n",
    "# Set the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Read the metadata file\n",
    "with open('metadata.txt', 'r') as f:\n",
    "    lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Shuffle the lines\n",
    "np.random.shuffle(lines)\n",
    "\n",
    "# Calculate the index for splitting the data\n",
    "split_idx = int(0.8 * len(lines))\n",
    "split_idx2 = int(0.9 * len(lines))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_lines = lines[:split_idx]\n",
    "valid_lines = lines[split_idx:split_idx2]\n",
    "test_lines = lines[split_idx2:]\n",
    "\n",
    "# Write the training data to a file\n",
    "with open('yolo7_detection/noise_speech_data/training.txt', 'w') as f:\n",
    "    for line in train_lines:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "# Write the validation data to a file\n",
    "with open('yolo7_detection/noise_speech_data/validation.txt', 'w') as f:\n",
    "    for line in valid_lines:\n",
    "        f.write(line + '\\n')\n",
    "        \n",
    "with open('yolo7_detection/noise_speech_data/test.txt', 'w') as f:\n",
    "    for line in test_lines:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print('train, validation and test data has been made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e11b0-c227-4328-9d96-082ca56eb5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
