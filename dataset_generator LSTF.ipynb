{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73bcbba4-cf7a-4254-9558-d89c17af2f99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 1.24 or less",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 63\u001b[0m\n\u001b[1;32m     59\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Load the wav file\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[43mconvert_audio_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_x2_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_csv\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m, in \u001b[0;36mconvert_audio_to_csv\u001b[0;34m(audio_file, output_file)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_audio_to_csv\u001b[39m(audio_file, output_file):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Load the audio file\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     SR \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m22050\u001b[39m  \u001b[38;5;66;03m# Assuming a sample rate of 22050 (replace with your desired value)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     y, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m(audio_file, sr\u001b[38;5;241m=\u001b[39mSR, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9730\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Create a progress bar\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     prog_bar \u001b[38;5;241m=\u001b[39m progressbar\u001b[38;5;241m.\u001b[39mProgressBar(maxval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(y))\n",
      "File \u001b[0;32m~/miniconda3/envs/LTSF39/lib/python3.9/site-packages/lazy_loader/__init__.py:78\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     76\u001b[0m submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m submod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(submod_path)\n\u001b[0;32m---> 78\u001b[0m attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m attr_to_modules[name]:\n",
      "File \u001b[0;32m~/miniconda3/envs/LTSF39/lib/python3.9/site-packages/lazy_loader/__init__.py:77\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[1;32m     76\u001b[0m     submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 77\u001b[0m     submod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(submod, name)\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/LTSF39/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/LTSF39/lib/python3.9/site-packages/librosa/core/audio.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msoxr\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlazy\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jit, stencil, guvectorize\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_fftlib\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frames_to_samples, time_to_samples\n",
      "File \u001b[0;32m~/miniconda3/envs/LTSF39/lib/python3.9/site-packages/numba/__init__.py:55\u001b[0m\n\u001b[1;32m     50\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba requires SciPy version 1.0 or greater. Got SciPy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscipy\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m---> 55\u001b[0m \u001b[43m_ensure_critical_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# END DO NOT MOVE\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# ---------------------- WARNING WARNING WARNING ----------------------------\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_versions\n",
      "File \u001b[0;32m~/miniconda3/envs/LTSF39/lib/python3.9/site-packages/numba/__init__.py:42\u001b[0m, in \u001b[0;36m_ensure_critical_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m numpy_version \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m24\u001b[39m):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 1.24 or less\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Numba needs NumPy 1.24 or less"
     ]
    }
   ],
   "source": [
    "# This code is to make *.csv dataset for LSTF from long wav files\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import csv\n",
    "import datetime\n",
    "import progressbar\n",
    "\n",
    "SR=22050\n",
    "\n",
    "\n",
    "def convert_audio_to_csv(audio_file, output_file):\n",
    "    # Load the audio file\n",
    "    SR = 22050  # Assuming a sample rate of 22050 (replace with your desired value)\n",
    "    y, sr = librosa.load(audio_file, sr=SR, duration=9730)\n",
    "\n",
    "    # Create a progress bar\n",
    "    prog_bar = progressbar.ProgressBar(maxval=len(y))\n",
    "\n",
    "    # Convert the audio to a CSV file\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "        # Write the header\n",
    "        writer.writerow(['date', 'waveform'])\n",
    "        prog_bar.start()\n",
    "\n",
    "        # Write the audio data to the CSV file\n",
    "        for i in range(len(y)):\n",
    "            timeframe = i / sr\n",
    "            frame_number = i\n",
    "            time_struct = datetime.timedelta(seconds=timeframe)\n",
    "\n",
    "            # Extract hours, minutes, and seconds directly from the timedelta object\n",
    "            hours, remainder = divmod(time_struct.seconds, 3600)\n",
    "            minutes, seconds = divmod(remainder, 60)\n",
    "            formatted_timeframe = f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "            writer.writerow([formatted_timeframe, y[i]])\n",
    "            prog_bar.update(i + 1)  # Update the progress bar with the current index\n",
    "        \n",
    "        prog_bar.finish()\n",
    "\n",
    "            \n",
    "            \n",
    "# Settings\n",
    "audio_y_file = 'C:/anc/data0213/audio_y.wav' # reverse audio of x2\n",
    "audio_x1_file = 'C:/anc/data0213/audio_x1.wav' # upstream recorded\n",
    "audio_x2_file = 'C:/anc/data0213/audio_x2.wav' # downstream recorded\n",
    "event_file = 'C:/hifi-gan/yolo7_detection/detection_results.txt' # event file(txt file). shape is (: , 4)\n",
    "output_dir = './dataset'\n",
    "dataset_csv = '/LTSF-Linear/dataset/audio_x2.csv'\n",
    "teacher_dir = 'C:/hifi-gan/yolo7_detection/noise_speech_data/teacher' # for fine tuning\n",
    "min_length_frames = SR*2 ## 2sec\n",
    "#total_length_frames = 215649000 ## 9780초\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the wav file\n",
    "\n",
    "convert_audio_to_csv(audio_x2_file, dataset_csv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b954bc70-4f84-4dde-a029-3f841c983dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.25.2'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96979aac-5f7f-4c58-9563-0387e8778568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.25.2'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51484dca-73ec-423e-bd38-f634b8bf6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "fps = 30\n",
    "\n",
    "\n",
    "audio_y, sr = librosa.load(audio_y_file, sr=SR)\n",
    "print('dimension of audio y :', audio_y.shape[0])\n",
    "print('time of audio(sec) : ', audio_y.shape[0]/SR)\n",
    "print('time of audio(min) : ', audio_y.shape[0]/SR/60)\n",
    "\n",
    "# Load the text file with specified columns and replace \"_\" in first column\n",
    "data = np.genfromtxt(event_file, delimiter=',', dtype=None, encoding=None)\n",
    "\n",
    "# Remove \"_\" from first column and convert to integer\n",
    "data['f0'] = np.char.replace(data['f0'], \"_\", \"\").astype(int)\n",
    "print('dimension of text data :', data.shape)\n",
    "print(data[0:5])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fd5d098-c4d9-415b-a8d3-8eac3d769db3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write the file until x1_segment_0.wav\n",
      "write the file until x1_segment_1.wav\n",
      "write the file until x1_segment_2.wav\n",
      "write the file until x1_segment_3.wav\n",
      "write the file until x1_segment_4.wav\n",
      "write the file until x1_segment_5.wav\n",
      "write the file until x1_segment_6.wav\n",
      "write the file until x1_segment_7.wav\n",
      "write the file until x1_segment_8.wav\n",
      "write the file until x1_segment_9.wav\n",
      "write the file until x1_segment_10.wav\n",
      "write the file until x1_segment_11.wav\n",
      "write the file until x1_segment_12.wav\n",
      "write the file until x1_segment_13.wav\n",
      "write the file until x1_segment_14.wav\n",
      "write the file until x1_segment_15.wav\n",
      "write the file until x1_segment_16.wav\n",
      "write the file until x1_segment_17.wav\n",
      "write the file until x1_segment_18.wav\n",
      "write the file until x1_segment_19.wav\n",
      "write the file until x1_segment_20.wav\n",
      "write the file until x1_segment_21.wav\n",
      "write the file until x1_segment_22.wav\n",
      "write the file until x1_segment_23.wav\n",
      "write the file until x1_segment_24.wav\n",
      "write the file until x1_segment_25.wav\n",
      "write the file until x1_segment_26.wav\n",
      "write the file until x1_segment_27.wav\n",
      "write the file until x1_segment_28.wav\n",
      "write the file until x1_segment_29.wav\n",
      "write the file until x1_segment_30.wav\n",
      "write the file until x1_segment_31.wav\n",
      "write the file until x1_segment_32.wav\n",
      "write the file until x1_segment_33.wav\n",
      "write the file until x1_segment_34.wav\n",
      "write the file until x1_segment_35.wav\n",
      "write the file until x1_segment_36.wav\n",
      "write the file until x1_segment_37.wav\n",
      "write the file until x1_segment_38.wav\n",
      "write the file until x1_segment_39.wav\n",
      "write the file until x1_segment_40.wav\n",
      "write the file until x1_segment_41.wav\n",
      "write the file until x1_segment_42.wav\n",
      "write the file until x1_segment_43.wav\n",
      "write the file until x1_segment_44.wav\n",
      "write the file until x1_segment_45.wav\n",
      "write the file until x1_segment_46.wav\n",
      "write the file until x1_segment_47.wav\n",
      "write the file until x1_segment_48.wav\n",
      "write the file until x1_segment_49.wav\n",
      "Noise speech data has been made.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Loop through the audio file with a step of segment_duration_s\n",
    "segment_duration_s = 2  # 2 seconds\n",
    "audio_duration_s = len(audio_x1) / SR\n",
    "\n",
    "# From config_v3.json, Hifi-GAN\n",
    "n_fft = 1024\n",
    "hop_size = 256\n",
    "win_size = 1024\n",
    "num_mels = 80\n",
    "sampling_rate = SR\n",
    "fmin = 0\n",
    "fmax = 8000\n",
    "\n",
    "# Create a list to store the metadata for each segment\n",
    "metadata = []\n",
    "\n",
    "for i in range(0, int(audio_duration_s - 100), segment_duration_s):\n",
    "    # Extract the segment\n",
    "    start_sample = i * SR\n",
    "    end_sample = (i + segment_duration_s) * SR\n",
    "    segment = audio_x1[start_sample:end_sample]\n",
    "    \n",
    "    # for Fine tuning .npy\n",
    "    segment_y = audio_y[start_sample:end_sample]\n",
    "    \n",
    "    # From meldataset.py\n",
    "    segment_y = torch.FloatTensor(segment_y)\n",
    "    segment_y = segment_y.unsqueeze(0)\n",
    "    \n",
    "    mel_spec = mel_spectrogram(segment_y, n_fft, num_mels, sampling_rate, hop_size, win_size, fmin, fmax, center=False)\n",
    "\n",
    "    #### 이전 버전 작업인데 차원이 맞지 않아서, Hifi-GAN에 있는 함수를 쓰기로.\n",
    "    #mel_spec = librosa.feature.melspectrogram(y=segment_y, sr=SR, n_mels=80, hop_length=256, n_fft=1024)\n",
    "    #mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # Save the segment\n",
    "    segment_name = f\"x1_segment_{i // segment_duration_s}.wav\"\n",
    "    segment_name_meta = f\"x1_segment_{i // segment_duration_s}\"\n",
    "    sf.write(segment_name, segment, SR)\n",
    "    \n",
    "    #파일 이름이 x1(입력과 동일한)으로 되어야 fine tuning이 동작됨.\n",
    "    segment_name_y = f\"x1_segment_{i // segment_duration_s}.npy\"\n",
    "    np.save(segment_name_y, mel_spec)\n",
    "    \n",
    "    if i & 100 == 0 :\n",
    "        print (f'progress on making training file until {segment_name}...') \n",
    "    \n",
    "    # Find the corresponding rows in the text file\n",
    "    start_time = i  # convert seconds to frames\n",
    "    end_time = i + segment_duration_s  # convert seconds to frames\n",
    "    frame_start = start_time * fps  # convert time to frames\n",
    "    frame_end = end_time * fps  # convert time to frames\n",
    "\n",
    "    # Select rows where the frame number is within the start and end frames\n",
    "    segment_metadata = data[(data['f0'].astype(int) >= frame_start) & (data['f0'].astype(int) < frame_end)]\n",
    "\n",
    "    # Keep only the columns you want (excluding the second and ninth)\n",
    "    segment_metadata = segment_metadata[['f2', 'f3', 'f4', 'f5', 'f6', 'f7']]\n",
    "    metadata_line = segment_name_meta\n",
    "    \n",
    "    # Add the segment metadata to the list\n",
    "    print('Start to making metadata..')\n",
    "    for j, row in enumerate(segment_metadata):\n",
    "        metadata_row = ', '.join(map(str, row))\n",
    "        if j == 0:\n",
    "            metadata_line += \"|\" + metadata_row\n",
    "        else:\n",
    "            metadata_line += \", \" + metadata_row\n",
    "    metadata.append(metadata_line)\n",
    "\n",
    "\n",
    "with open(\"metadata.txt\", 'w') as f:\n",
    "    for line in metadata:\n",
    "        f.write(line + \"\\n\")\n",
    "        \n",
    "print('Noise speech data has been made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29feda2-64c8-4f25-ab1c-61ea1b025b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, validation and test data has been made.\n"
     ]
    }
   ],
   "source": [
    "# To Split train and validation data\n",
    "\n",
    "# Set the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Read the metadata file\n",
    "with open('metadata.txt', 'r') as f:\n",
    "    lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Shuffle the lines\n",
    "np.random.shuffle(lines)\n",
    "\n",
    "# Calculate the index for splitting the data\n",
    "split_idx = int(0.8 * len(lines))\n",
    "split_idx2 = int(0.9 * len(lines))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_lines = lines[:split_idx]\n",
    "valid_lines = lines[split_idx:split_idx2]\n",
    "test_lines = lines[split_idx2:]\n",
    "\n",
    "# Write the training data to a file\n",
    "with open('yolo7_detection/noise_speech_data/training.txt', 'w') as f:\n",
    "    for line in train_lines:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "# Write the validation data to a file\n",
    "with open('yolo7_detection/noise_speech_data/validation.txt', 'w') as f:\n",
    "    for line in valid_lines:\n",
    "        f.write(line + '\\n')\n",
    "        \n",
    "with open('yolo7_detection/noise_speech_data/test.txt', 'w') as f:\n",
    "    for line in test_lines:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print('train, validation and test data has been made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e11b0-c227-4328-9d96-082ca56eb5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
